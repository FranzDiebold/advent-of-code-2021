{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9be54b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e83fcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/04 08:57:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .appName(\"advent-of-code-2021\") \\\n",
    "            .master(\"local[*]\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1e95b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = spark.read.text(\"test-input.txt\")\n",
    "df = spark.read.text(\"input.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49844be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: 3549854\n"
     ]
    }
   ],
   "source": [
    "# Part 1\n",
    "def part_1(df):\n",
    "    number_of_bits = len(df.first()[\"value\"])\n",
    "    number_of_rows = df.count()\n",
    "\n",
    "    bit_columns = []\n",
    "    sum_aggregations = []\n",
    "    for i in range(number_of_bits):\n",
    "        bit_columns.append(F.substring(\"value\", i + 1, 1).cast(\"int\").alias(f\"bit_{i}\"))\n",
    "        sum_aggregations.append(F.sum(f\"bit_{i}\").alias(f\"sum_{i}\"))\n",
    "\n",
    "    df = df \\\n",
    "        .select(*bit_columns) \\\n",
    "        .agg(*sum_aggregations)\n",
    "\n",
    "    most_common_columns = []\n",
    "    most_common_columns_names = []\n",
    "    for i in range(number_of_bits):\n",
    "        most_common_columns.append(F.round(F.col(f\"sum_{i}\") / number_of_rows).cast(\"int\").alias(f\"most_common_{i}\"))\n",
    "        most_common_columns_names.append(f\"most_common_{i}\")\n",
    "\n",
    "    df = df \\\n",
    "        .select(*most_common_columns) \\\n",
    "        .select(most_common_columns_names)\n",
    "\n",
    "    gamma_bits = list(df.collect()[0])\n",
    "    epsilon_bits = [abs(1 - gamma_bit) for gamma_bit in gamma_bits]\n",
    "\n",
    "    gamma = int(\"\".join([str(b) for b in gamma_bits]), 2)\n",
    "    epsilon = int(\"\".join([str(b) for b in epsilon_bits]), 2)\n",
    "\n",
    "    return gamma * epsilon\n",
    "\n",
    "assert part_1(df_test) == 198\n",
    "\n",
    "print(f\"Solution: {part_1(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a6f7f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: 3765399\n"
     ]
    }
   ],
   "source": [
    "# Part 2\n",
    "def _get_rating(df, rating_type):\n",
    "    number_of_bits = len(df.first()[\"value\"])\n",
    "\n",
    "    filtered_df = df\n",
    "    for i in range(number_of_bits):\n",
    "        number_of_rows = filtered_df.count()\n",
    "        if number_of_rows == 1:\n",
    "            break\n",
    "\n",
    "        filtered_df = filtered_df.withColumn(f\"bit_{i}\", F.substring(\"value\", i + 1, 1).cast(\"int\"))\n",
    "        sum_df = filtered_df.agg(F.sum(f\"bit_{i}\").alias(f\"sum_{i}\"))\n",
    "        sum_i = sum_df.collect()[0][0]\n",
    "\n",
    "        ones_ratio = sum_i / number_of_rows\n",
    "        if ones_ratio != 0.5:\n",
    "            most_common = round(ones_ratio)\n",
    "            least_common = abs(1 - most_common)\n",
    "        else:\n",
    "            most_common = 1\n",
    "            least_common = 0\n",
    "\n",
    "        filter_value = most_common if rating_type == \"oxygen\" else least_common\n",
    "        filtered_df = filtered_df.filter(F.col(f\"bit_{i}\") == filter_value)\n",
    "\n",
    "    if filtered_df.count() == 1:\n",
    "        return filtered_df.first()[0]\n",
    "    else:\n",
    "        raise ValueError(f\"No rating found for {rating_type}\")\n",
    "\n",
    "def part_2(df):\n",
    "    oxygen_rating = int(_get_rating(df, \"oxygen\"), 2)\n",
    "    co2_rating = int(_get_rating(df, \"co2\"), 2)\n",
    "    return oxygen_rating * co2_rating        \n",
    "\n",
    "assert part_2(df_test) == 230\n",
    "\n",
    "print(f\"Solution: {part_2(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d9a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
